{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Breast Cancer data from [the UCI repository](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) contains records corresponding to \n",
    "cases of observed tumors.   There are a number of observations for each and a categorisation in the `class` column: 2 for benign (good), 4 for malignant (bad).  Your task is to build a logistic regression model to classify these cases. \n",
    "\n",
    "The data is provided as a CSV file.  There are a small number of cases where no value is available, these are indicated in the data with `?`. I have used the `na_values` keyword for `read_csv` to have these interpreted as `NaN` (Not a Number).  Your first task is to decide what to do with these rows. You could just drop these rows or you could [impute them from the other data](http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values).\n",
    "\n",
    "You then need to follow the procedure outlined in the lecture for generating a train/test set, building and evaluating a model. Your goal is to build the best model possible over this data.   Your first step should be to build a logistic regression model using all of the features that are available.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_code_number</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>uniformity_cell_size</th>\n",
       "      <th>uniformity_cell_shape</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>single_epithelial_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_code_number  clump_thickness  uniformity_cell_size  \\\n",
       "0             1000025                5                     1   \n",
       "1             1002945                5                     4   \n",
       "2             1015425                3                     1   \n",
       "3             1016277                6                     8   \n",
       "4             1017023                4                     1   \n",
       "\n",
       "   uniformity_cell_shape  marginal_adhesion  single_epithelial_cell_size  \\\n",
       "0                      1                  1                            2   \n",
       "1                      4                  5                            7   \n",
       "2                      1                  1                            2   \n",
       "3                      8                  1                            3   \n",
       "4                      1                  3                            2   \n",
       "\n",
       "   bare_nuclei  bland_chromatin  normal_nucleoli  mitoses  class  \n",
       "0          1.0                3                1        1      2  \n",
       "1         10.0                3                2        1      2  \n",
       "2          2.0                3                1        1      2  \n",
       "3          4.0                3                7        1      2  \n",
       "4          1.0                3                1        1      2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer = pd.read_csv(\"data/breast-cancer-wisconsin.csv\", na_values=\"?\")\n",
    "bcancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_code_number</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>uniformity_cell_size</th>\n",
       "      <th>uniformity_cell_shape</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>single_epithelial_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_code_number  clump_thickness  uniformity_cell_size  \\\n",
       "count        6.990000e+02       699.000000            699.000000   \n",
       "mean         1.071704e+06         4.417740              3.134478   \n",
       "std          6.170957e+05         2.815741              3.051459   \n",
       "min          6.163400e+04         1.000000              1.000000   \n",
       "25%          8.706885e+05         2.000000              1.000000   \n",
       "50%          1.171710e+06         4.000000              1.000000   \n",
       "75%          1.238298e+06         6.000000              5.000000   \n",
       "max          1.345435e+07        10.000000             10.000000   \n",
       "\n",
       "       uniformity_cell_shape  marginal_adhesion  single_epithelial_cell_size  \\\n",
       "count             699.000000         699.000000                   699.000000   \n",
       "mean                3.207439           2.806867                     3.216023   \n",
       "std                 2.971913           2.855379                     2.214300   \n",
       "min                 1.000000           1.000000                     1.000000   \n",
       "25%                 1.000000           1.000000                     2.000000   \n",
       "50%                 1.000000           1.000000                     2.000000   \n",
       "75%                 5.000000           4.000000                     4.000000   \n",
       "max                10.000000          10.000000                    10.000000   \n",
       "\n",
       "       bare_nuclei  bland_chromatin  normal_nucleoli     mitoses       class  \n",
       "count   683.000000       699.000000       699.000000  699.000000  699.000000  \n",
       "mean      3.544656         3.437768         2.866953    1.589413    2.689557  \n",
       "std       3.643857         2.438364         3.053634    1.715078    0.951273  \n",
       "min       1.000000         1.000000         1.000000    1.000000    2.000000  \n",
       "25%       1.000000         2.000000         1.000000    1.000000    2.000000  \n",
       "50%       1.000000         3.000000         1.000000    1.000000    2.000000  \n",
       "75%       6.000000         5.000000         4.000000    1.000000    4.000000  \n",
       "max      10.000000        10.000000        10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_code_number              0\n",
       "clump_thickness                 0\n",
       "uniformity_cell_size            0\n",
       "uniformity_cell_shape           0\n",
       "marginal_adhesion               0\n",
       "single_epithelial_cell_size     0\n",
       "bare_nuclei                    16\n",
       "bland_chromatin                 0\n",
       "normal_nucleoli                 0\n",
       "mitoses                         0\n",
       "class                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_bcancer = bcancer.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_bcancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your first model - defining training and test data sets then use Logistic Regression to build a model\n",
    "train, test = train_test_split(clean_bcancer, test_size=0.2, random_state=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (546, 11)\n",
      "Test shape: (137, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (546, 9)\n",
      "Y_train shape: (546,)\n",
      "X_test shape: (137, 9)\n",
      "Y_test shape: (137,)\n"
     ]
    }
   ],
   "source": [
    "x_train= train.drop(['sample_code_number', 'class' ], axis=1)\n",
    "y_train = train['class']\n",
    "\n",
    "x_test = test.drop(['sample_code_number', 'class' ], axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "print('X_train shape:',x_train.shape )\n",
    "print('Y_train shape:',y_train.shape )\n",
    "print('X_test shape:',x_test.shape )\n",
    "print('Y_test shape:',y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "#training model on the training set\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "To evaluate a classification model we want to look at how many cases were correctly classified and how many\n",
    "were in error.  In this case we have two outcomes - benign and malignant.   SKlearn has some useful tools, the \n",
    "[accuracy_score]() function gives a score from 0-1 for the proportion correct.  The \n",
    "[confusion_matrix](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) function \n",
    "shows how many were classified correctly and what errors were made.  Use these to summarise the performance of \n",
    "your model (these functions have already been imported above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 4,\n",
       "       2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2,\n",
       "       4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4,\n",
       "       2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2,\n",
       "       2, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 2,\n",
       "       2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280    2\n",
       "232    2\n",
       "369    2\n",
       "563    2\n",
       "491    4\n",
       "320    4\n",
       "327    2\n",
       "270    4\n",
       "63     4\n",
       "187    4\n",
       "50     4\n",
       "632    2\n",
       "45     2\n",
       "304    4\n",
       "573    2\n",
       "561    2\n",
       "679    2\n",
       "135    2\n",
       "13     2\n",
       "384    2\n",
       "169    2\n",
       "527    2\n",
       "167    4\n",
       "198    2\n",
       "671    2\n",
       "502    2\n",
       "255    4\n",
       "538    2\n",
       "470    2\n",
       "105    4\n",
       "      ..\n",
       "589    2\n",
       "523    4\n",
       "143    2\n",
       "602    2\n",
       "425    4\n",
       "609    2\n",
       "218    4\n",
       "72     2\n",
       "281    2\n",
       "279    4\n",
       "124    4\n",
       "672    2\n",
       "510    2\n",
       "347    2\n",
       "4      2\n",
       "247    4\n",
       "122    4\n",
       "354    2\n",
       "667    2\n",
       "177    4\n",
       "365    2\n",
       "233    4\n",
       "615    2\n",
       "419    2\n",
       "432    2\n",
       "645    2\n",
       "353    4\n",
       "307    2\n",
       "126    4\n",
       "67     4\n",
       "Name: class, Length: 137, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set:\n",
      "0.9635036496350365\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy_score on test set\n",
    "print(\"Accuracy score on test set:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  2]\n",
      " [ 3 49]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#diagnoal elements are correctly classified 132/137 = 0.963\n",
    "#TN FN\n",
    "#FP TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Since you have many features available, one part of building the best model will be to select which features to use as input to the classifier. Your initial model used all of the features but it is possible that a better model can \n",
    "be built by leaving some of them out.   Test this by building a few models with subsets of the features - how do your models perform? \n",
    "\n",
    "This process can be automated.  The [sklearn RFE function](http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination) implements __Recursive Feature Estimation__ which removes \n",
    "features one by one, evaluating the model each time and selecting the best model for a target number of features.  Use RFE to select features for a model with 3, 4 and 5 features - can you build a model that is as good or better than your initial model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on test set: 0.9562043795620438\n",
      "[ True  True False  True False  True  True False False]\n",
      "Important features:  Index(['clump_thickness', 'uniformity_cell_size', 'marginal_adhesion',\n",
      "       'bare_nuclei', 'bland_chromatin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFE(estimator, 5, step=1)\n",
    "selector.fit(x_train, y_train)\n",
    "y_predict = selector.predict(x_test)\n",
    "print('Acc on test set:', accuracy_score(y_test, y_predict))\n",
    "print(selector.support_)\n",
    "colNames = x_train.columns\n",
    "print(\"Important features: \", colNames[selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on test set: 0.9635036496350365\n",
      "[ True  True False False False  True  True False False]\n",
      "Important features:  Index(['clump_thickness', 'uniformity_cell_size', 'bare_nuclei',\n",
      "       'bland_chromatin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFE(estimator, 4, step=1)\n",
    "selector.fit(x_train, y_train)\n",
    "y_predict = selector.predict(x_test)\n",
    "print('Acc on test set:', accuracy_score(y_test, y_predict))\n",
    "print(selector.support_)\n",
    "colNames = x_train.columns\n",
    "print(\"Important features: \", colNames[selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on test set: 0.9562043795620438\n",
      "[False  True False False False  True  True False False]\n",
      "Important features:  Index(['uniformity_cell_size', 'bare_nuclei', 'bland_chromatin'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFE(estimator, 3, step=1)\n",
    "selector.fit(x_train, y_train)\n",
    "y_predict = selector.predict(x_test)\n",
    "print('Acc on test set:', accuracy_score(y_test, y_predict))\n",
    "print(selector.support_)\n",
    "colNames = x_train.columns\n",
    "print(\"Important features: \", colNames[selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on test set: 0.9124087591240876\n",
      "[False  True False False False False False False False]\n",
      "Important features:  Index(['uniformity_cell_size'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFE(estimator, 1, step=1)\n",
    "selector.fit(x_train, y_train)\n",
    "y_predict = selector.predict(x_test)\n",
    "print('Acc on test set:', accuracy_score(y_test, y_predict))\n",
    "print(selector.support_)\n",
    "colNames = x_train.columns\n",
    "print(\"Important features: \", colNames[selector.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Write a brief conclusion to your experiment.  You might comment on the proportion of __false positive__ and __false negative__ classifications your model makes.  How useful would this model be in a clinical diagnostic setting? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important features are: \n",
    "* clump_thickness\n",
    "* uniformity_cell_size\n",
    "* bare_nuclei\n",
    "* bland_chromatin\n",
    "\n",
    "Giving an accuracy score of: 0.96350\n",
    "\n",
    "* True negative = 83\n",
    "* True positive = 49\n",
    "* False positives = 3 \n",
    "* False negatives = 2\n",
    "\n",
    "\n",
    "This accruacy is not sufficient for a clinical setting as it would mis-diagnose a large amount of patients.\n",
    "* 4/100\n",
    "* 40/1000\n",
    "* 40000/100000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
